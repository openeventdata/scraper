[Database]
collection_list = stories

[URLS]
file = whitelist_urls.csv
sources = wire,international,local

[Processes]
pool_size = 30

[Logging]
log_file = scraper_log.log
#Can set to debug, info, warning. If debug there will be a lot of information.
#If info there will be entries about new additions to the database and errors.
#If warning will only be errors thrown by the scraper.
level = info

#[Auth]
#auth_db = db_name
#auth_user = username
#auth_pass = password
